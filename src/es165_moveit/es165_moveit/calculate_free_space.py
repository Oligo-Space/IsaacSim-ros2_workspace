"""Workspace analysis using cuRobo with systematic grid sampling and collision checking"""
"""Partially generated by Claude Opus 4.5, verified in production, updated via Phillip"""

import torch
import numpy as np
import trimesh
from itertools import product
import time

from curobo.types.robot import RobotConfig
from curobo.types.base import TensorDeviceType
from curobo.types.math import Pose
from curobo.wrap.model.robot_world import RobotWorld, RobotWorldConfig
from curobo.wrap.reacher.ik_solver import IKSolver, IKSolverConfig
from curobo.geom.types import WorldConfig, Mesh, Cuboid
from curobo.geom.sdf.world import CollisionQueryBuffer
from curobo.wrap.reacher.motion_gen import MotionGen, MotionGenConfig, MotionGenPlanConfig
from curobo.types.state import JointState

import time


def euler_from_quaternion(qx, qy, qz, qw):
    t0 = +2.0 * (qw * qw + qz * qz) - 1.0
    t1 = -2.0 * (qx * qx + qy * qy) + 1.0
    t2 = +2.0 * (qx * qz + qw * qy)
    t3 = +2.0 * (qy * qz - qw * qx)
    roll = np.arctan2(t2, t1)
    pitch = np.arcsin(t0)
    yaw = np.arctan2(t3, t2)
    return roll, pitch, yaw

def euler_to_quaternion(roll, pitch, yaw):
    """Convert Euler angles (roll, pitch, yaw) to quaternion (qx, qy, qz, qw)."""
    cy = np.cos(yaw * 0.5)
    sy = np.sin(yaw * 0.5)
    cp = np.cos(pitch * 0.5)
    sp = np.sin(pitch * 0.5)
    cr = np.cos(roll * 0.5)
    sr = np.sin(roll * 0.5)
    
    qw = cr * cp * cy + sr * sp * sy
    qx = sr * cp * cy - cr * sp * sy
    qy = cr * sp * cy + sr * cp * sy
    qz = cr * cp * sy - sr * sp * cy
    
    return qx, qy, qz, qw

# def check_ground_plane(*args):
#     x, y, z, roll, pitch, yaw = args
#     # if elif used for clarity instead of a one liner
#     if (z - BOARD_WIDTH*np.abs(np.sin(pitch))) < MIN_HEIGHT:
#         return False
#     elif (z - BOARD_LENGTH*np.abs(np.sin(roll))) < MIN_HEIGHT:
#         return False
#     return True

def get_collision_signed_distance(curobo_fn, q_batch, tensor_args):
    """Get actual signed distance for collision checking.
    
    Returns:
        d_world: [batch, num_spheres] - positive = free, negative = collision
        d_self: [batch] - minimum self-collision distance per config (positive = free)
    """
    state = curobo_fn.kinematics.get_state(q_batch)
    spheres = state.link_spheres_tensor.unsqueeze(1)

    wcc = curobo_fn.collision_cost.world_coll_checker
    query_buffer = CollisionQueryBuffer()
    query_buffer.update_buffer_shape(spheres.shape, tensor_args, wcc.collision_types)
    
    d_world = wcc.get_sphere_collision(
        spheres,
        query_buffer,
        weight=torch.tensor([1.0], device=tensor_args.device),
        activation_distance=torch.tensor([0.05], device=tensor_args.device),
        return_loss=False,
        sum_collisions=False,
        compute_esdf=False,
    )
    print(f"d_world: {d_world}")
    
    # Self-collision distance - may return per-pair distances
    d_self_raw = curobo_fn.get_self_collision_distance(spheres)
    # Aggregate to get minimum distance per configuration (if multi-dimensional)
    if d_self_raw.dim() > 1:
        d_self = d_self_raw.min(dim=-1)[0]
        if d_self.dim() > 1:
            d_self = d_self.squeeze(1)
    else:
        d_self = d_self_raw
    
    return d_world.squeeze(1), d_self


class WorkspaceGridSampler:
    """Systematic grid-based workspace sampler with reach filtering."""
    
    def __init__(
        self,
        position_bounds: dict,
        orientation_bounds: dict,
        position_steps: dict,
        orientation_steps: dict,
        max_reach: float = None,  # Filter poses beyond this distance from origin
        min_reach: float = 0.0,   # Filter poses closer than this distance
    ):
        """
        Args:
            position_bounds: {'x': (min, max), 'y': (min, max), 'z': (min, max)}
            orientation_bounds: {'roll': (min, max), 'pitch': (min, max), 'yaw': (min, max)}
            position_steps: {'x': step, 'y': step, 'z': step}
            orientation_steps: {'roll': step, 'pitch': step, 'yaw': step}
            max_reach: Maximum distance from robot base to consider (filters far poses)
            min_reach: Minimum distance from robot base to consider (filters too-close poses)
        """
        self.position_bounds = position_bounds
        self.orientation_bounds = orientation_bounds
        self.position_steps = position_steps
        self.orientation_steps = orientation_steps
        self.max_reach = max_reach
        self.min_reach = min_reach
        
        # Generate grid points
        self.x_range = np.arange(position_bounds['x'][0], position_bounds['x'][1] + position_steps['x']/2, position_steps['x'])
        self.y_range = np.arange(position_bounds['y'][0], position_bounds['y'][1] + position_steps['y']/2, position_steps['y'])
        self.z_range = np.arange(position_bounds['z'][0], position_bounds['z'][1] + position_steps['z']/2, position_steps['z'])
        self.roll_range = np.arange(orientation_bounds['roll'][0], orientation_bounds['roll'][1], orientation_steps['roll'])
        self.pitch_range = np.arange(orientation_bounds['pitch'][0], orientation_bounds['pitch'][1], orientation_steps['pitch'])
        self.yaw_range = np.arange(orientation_bounds['yaw'][0], orientation_bounds['yaw'][1], orientation_steps['yaw'])
        
        # Count total valid samples (considering reach filter)
        self.total_samples = 0
        self.filtered_samples = 0
        for x in self.x_range:
            for y in self.y_range:
                for z in self.z_range:
                    dist = np.sqrt(x**2 + y**2 + z**2)
                    if max_reach is not None and dist > max_reach:
                        self.filtered_samples += len(self.roll_range) * len(self.pitch_range) * len(self.yaw_range)
                        continue
                    if dist < min_reach:
                        self.filtered_samples += len(self.roll_range) * len(self.pitch_range) * len(self.yaw_range)
                        continue
                    self.total_samples += len(self.roll_range) * len(self.pitch_range) * len(self.yaw_range)


    def generate_poses_batch(self, batch_size: int = 1000):
        """Generate poses in batches for efficient GPU processing.
        
        Yields:
            Tuple of (positions, quaternions, euler_angles) as numpy arrays
            positions: (batch, 3) - x, y, z
            quaternions: (batch, 4) - qw, qx, qy, qz (cuRobo convention)
            euler_angles: (batch, 3) - roll, pitch, yaw (for reference)
        """
        batch_positions = []
        batch_quaternions = []
        batch_euler = []
        
        for x, y, z in product(self.x_range, self.y_range, self.z_range):
            # Filter by reach distance
            dist = np.sqrt(x**2 + y**2 + z**2)
            if self.max_reach is not None and dist > self.max_reach:
                continue
            if dist < self.min_reach:
                continue
                
            for roll, pitch, yaw in product(self.roll_range, self.pitch_range, self.yaw_range):
                qx, qy, qz, qw = euler_to_quaternion(roll, pitch, yaw)

                
                batch_positions.append([x, y, z])
                batch_quaternions.append([qw, qx, qy, qz])  # cuRobo uses wxyz
                batch_euler.append([roll, pitch, yaw])
                
                if len(batch_positions) >= batch_size:
                    yield (
                        np.array(batch_positions),
                        np.array(batch_quaternions),
                        np.array(batch_euler)
                    )
                    batch_positions = []
                    batch_quaternions = []
                    batch_euler = []
        
        # Yield remaining
        if batch_positions:
            yield (
                np.array(batch_positions),
                np.array(batch_quaternions),
                np.array(batch_euler)
            )


if __name__ == "__main__":
    from curobo.cuda_robot_model.cuda_robot_model import CudaRobotGeneratorConfig, CudaRobotGenerator
    from curobo.types.base import TensorDeviceType
    from curobo.util_file import get_robot_configs_path, join_path, load_yaml

    robot_file = "/home/oligo/IsaacSim-ros_workspaces/humble_ws/src/es165_moveit/old_cuda_stuff/robot_description.yaml"
    mesh_path = "/home/oligo/IsaacSim-ros_workspaces/humble_ws/src/es165_moveit/usd/scene_mesh.stl"
    urdf_file = "/home/oligo/IsaacSim-ros_workspaces/humble_ws/src/es165_moveit/urdf/es165.urdf"
    # ground_plane_file = "/home/oligo/IsaacSim-ros_workspaces/humble_ws/src/es165_moveit/urdf/ground_plane_only.yaml"
    tensor_args = TensorDeviceType()

    # === Load World Model ===
    print("Loading mesh...")
    tri_mesh = trimesh.load(mesh_path)
    print(f"Mesh loaded: {len(tri_mesh.vertices)} vertices, {len(tri_mesh.faces)} faces")

    MIN_HEIGHT = 0.2
    BOARD_WIDTH = 0.51
    BOARD_LENGTH = 1.17
    #find the poses that make it so any part of the board is <0.2

    
    # q = euler_to_quaternion(np.radians(0.0), np.radians(180.0), np.radians(90.0))
    q = euler_to_quaternion(np.radians(0.0), np.radians(0.0), np.radians(0.0))
    # place the scene at the origin
    pose = [0.0, 0.0, -0.05, q[0], q[1], q[2], q[3]]
    scene_mesh = Mesh(
        name="scene",
        pose=pose,
        vertices=tri_mesh.vertices.tolist(),
        faces=tri_mesh.faces.tolist(),
    )

    # INSERT_YOUR_CODE
    # Create a WorldConfig with only the ground plane as an obstacle
    world_config = WorldConfig(
        cuboid=[
            Cuboid(
                name="ground_plane",
                pose=[0.0, 0.0, -0.05, q[0], q[1], q[2], q[3]],
                dims=[10.0, 10.0, 0.01]
            )
        ]
    )

    # world_config = WorldConfig(mesh=[scene_mesh],)
    # world_config.save_world_as_mesh("test.obj")
    # world_config = WorldConfig()
    # world_config = WorldConfig.from_dict(load_yaml(ground_plane_file))
    # Load robot configuration directly from YAML using RobotConfig loader
    config = RobotWorldConfig.load_from_config(
        robot_file,
        world_config,
        collision_activation_distance=0.01
    )
    curobo_fn = RobotWorld(config)
    

    kin_cfg_file = load_yaml(robot_file)
    base_link = kin_cfg_file["robot_cfg"]["kinematics"]["base_link"]
    ee_link = kin_cfg_file["robot_cfg"]["kinematics"]["ee_link"]
    ik_cfg = RobotConfig.from_basic(
        urdf_file,
        base_link,
        ee_link,
        tensor_args
    )
    
    # === Create IK Solver with collision checking ===
    print("Setting up IK solver...")
    ik_config = IKSolverConfig.load_from_robot_config(
        robot_cfg = ik_cfg,
        world_model =world_config,
        rotation_threshold=0.05,
        position_threshold=0.02,
        num_seeds=20,  # Number of IK seeds to try
        self_collision_check=True,
        self_collision_opt=True,
        tensor_args=tensor_args,
        use_cuda_graph=True,  # Disabled to allow variable batch sizes
    )
    ik_solver = IKSolver(ik_config)

    dt = 1/100

    def deprecated_code():
        '''
        testing code that is still relevant as it contains
        useful info about setting up path planning and motion generation
        kept inside a function so that it can be easily truncated
        '''
        # motion_gen_config = MotionGenConfig.load_from_robot_config(
        #     ik_cfg,
        #     world_model = world_config,
        #     tensor_args=tensor_args,
        #     interpolation_dt=dt,
        #     use_cuda_graph=True,
        #     num_trajopt_seeds=6,
        #     num_ik_seeds=6,
        #     position_threshold=0.02,
        #     rotation_threshold=0.1,
            
        #     # trajopt_tsteps=16
            
        # )
        # motion_gen = MotionGen(motion_gen_config)
        # # Testing
        # p = (2.0,2.0,1.0)
        # # r = np.deg2rad([0.0,-180.0,60.0])
        # r = np.deg2rad([0.0,0.0,10.0])
        # position_tensor = torch.from_numpy(np.asarray(p, dtype=np.float32)).to(tensor_args.device)
        # print(f"check_ground_plane: {check_ground_plane(*p,*r)}")
        # q = euler_to_quaternion(*r)
        # print(f"q: {q}")
        # # check something like this but facing downward
        # # quaternion_tensor = torch.from_numpy(np.asarray(q, dtype=np.float32)).to(tensor_args.device)
        # # result = ik_solver.solve_single(Pose(position=position_tensor, quaternion=quaternion_tensor))
        # # print(result.success)
        # # print(result.solution)
        # # valid_joints = result.solution[0, 0, :].reshape(1,6)
        # # print(valid_joints)

        # start_state = JointState.from_numpy(
        #     position=np.deg2rad(np.array([-11,-61,19,-8,-46,109])).reshape(1,6),
        #     joint_names=["joint_1_s", "joint_2_l", "joint_3_u", "joint_4_r", "joint_5_b", "joint_6_t"]
        # )
        # # print(f"start_state: {start_state}")

        # # Get cartesian position (end-effector pose) from given joint state using the IK solver's FK capability.
        # # valid_joints is expected to have shape (1,6)
        # fk_result = ik_solver.fk(torch.from_numpy(np.asarray(np.deg2rad(np.array([-11,-61,19,-8,-46,109])).reshape(1,6), dtype=np.float32)).to(tensor_args.device))

        # print(f"fk_result: {fk_result}")
        # # fk_result is a Pose, likely a batch of 1
        # # To get position as numpy array:
        # # cartesian_position = fk_result.position.cpu().numpy()[0]  # (x, y, z)
        # # cartesian_quaternion = fk_result.quaternion.cpu().numpy()[0]  # (qx, qy, qz, qw)
        # # print("Cartesian Position from FK:", cartesian_position)
        # # print("Cartesian Quaternion from FK:", cartesian_quaternion)

        # # goal_pose = Pose.from_list([2.0, 2.0, 1.0, q[0], q[1], q[2], q[3]])
        # # print(f' motion gen result: {motion_gen.solve_ik(goal_pose)}')
        # # print(f' ik solver result: {ik_solver.solve_single(goal_pose)}')
        # joint_state = np.deg2rad(np.array([-11,-61,19,-8,-46,109])).reshape(1,6)
        # joint_velocity = np.array([0.0,0.0,0.0,0.0,0.0,0.0]).reshape(1,6)
        # joint_acceleration = np.array([0.0,0.0,0.0,0.0,0.0,0.0]).reshape(1,6)
        # # joint_state = np.deg2rad(np.array([-11,-61,19,-8,-46,109]))
        # # joint_velocity = np.array([0.0,0.0,0.0,0.0,0.0,0.0])
        # # joint_acceleration = np.array([0.0,0.0,0.0,0.0,0.0,0.0])
        # start_state = JointState.from_numpy(
        #     position=joint_state,
        #     velocity=joint_velocity,
        #     acceleration=joint_acceleration,
        #     joint_names=["joint_1_s", "joint_2_l", "joint_3_u", "joint_4_r", "joint_5_b", "joint_6_t"]
        # )
        # print(f'start_angles: {motion_gen.solve_fk(start_state)}')
        # t = np.array([0.33,0.0,0.0])
        # p = [ 2.6286, -0.4880,  1.3043]
        # q = [0.2215, 0.6498, 0.6992, 0.1997]
        # angles = euler_from_quaternion(q[0],q[1],q[2],q[3])
        # q = np.array([q[0],q[1],q[2],q[3]])
        # w = np.array([0.0,0.0,0.0])
        
        # w_q = euler_to_quaternion(w[0],w[1],w[2])
        # # print(f"goal_pose: {goal_pose}")
        # for i in range(1,20):

        #     start_state = JointState.from_numpy(
        #         position=joint_state,
        #         velocity=joint_velocity,
        #         acceleration=joint_acceleration,
        #         joint_names=["joint_1_s", "joint_2_l", "joint_3_u", "joint_4_r", "joint_5_b", "joint_6_t"]
        #     )
        #     print(f'start angles: {angles}')
        #     w = w + t*dt
        #     angles = angles + w*dt
        #     # p = p + w*dt
        #     print(f'goal angles: {angles}')
        #     q = euler_to_quaternion(angles[0],angles[1],angles[2])
        #     goal_pose = Pose.from_list([p[0],p[1],p[2],q[0],q[1],q[2],q[3]])
        #     result = motion_gen.plan_single(start_state, goal_pose)
        #     print(f'result.success: {result.success}')
        #     print(f'result.solve_time: {result.solve_time}')
        #     print(f'result.ik_time: {result.ik_time}')
        #     print(f'result.attempts: {result.attempts}')
        #     # print(f'result.interpolated_plan: {result.interpolated_plan}')
        #     joint_state = result.interpolated_plan.position[-1, :].reshape(1,6)
        #     print(f'initial state: {start_state.position}')
        #     print(f'final state: {joint_state}')
        #     print(f'initial position: {p}')
        #     print(f'final position: {ik_solver.fk(joint_state).ee_position}')
        #     joint_velocity = result.interpolated_plan.velocity[-1, :].reshape(1,6)
        #     joint_acceleration = result.interpolated_plan.acceleration[-1, :].reshape(1,6)
        # # print(result)
        # exit(0)
        
        # # dw,ds = curobo_fn.get_world_self_collision_distance_from_joints(valid_joints)
        # # print(dw)
        # # print(ds)
        # d_world, d_self = get_collision_signed_distance(curobo_fn, valid_joints, tensor_args)
        # print(d_world)
        # print(d_self)
        # exit(0)
        return

    position_bounds = {
        'x': (-4.0, 4.0),
        'y': (-4.0, 4.0),
        'z': (0.0, 4.0),
    }

    orientation_bounds = {
        'roll': (-np.pi, np.pi),
        'pitch': (-np.pi, np.pi),
        'yaw': (-np.pi, np.pi),
    }
    # Coarser default steps for faster initial analysis
    # Adjust these for finer resolution (but more compute time)
    position_steps = {
        'x': 0.1,   # 25cm steps
        'y': 0.1,
        'z': 0.25,
    }

    orientation_steps = {
        'roll': np.deg2rad(45),   # 45° steps
        'pitch': np.deg2rad(45),
        'yaw': np.deg2rad(90),    # 90° steps
    }


    # IK solver batch size (process this many poses at once)
    ik_batch_size = 3000  # Larger batch for better GPU utilization

    

    ROBOT_MAX_REACH = 4.0
    ROBOT_MIN_REACH = 0.1

    
    # === Create Grid Sampler ===
    sampler = WorkspaceGridSampler(
        position_bounds=position_bounds,
        orientation_bounds=orientation_bounds,
        position_steps=position_steps,
        orientation_steps=orientation_steps,
        max_reach=ROBOT_MAX_REACH,  # Filter poses beyond robot reach
        min_reach=ROBOT_MIN_REACH,  # Filter poses too close to base
    )
    
    print(f"\n=== Workspace Grid Analysis ===")
    print(f"Position ranges:")
    print(f"  X: {position_bounds['x']} step {position_steps['x']} -> {len(sampler.x_range)} points")
    print(f"  Y: {position_bounds['y']} step {position_steps['y']} -> {len(sampler.y_range)} points")
    print(f"  Z: {position_bounds['z']} step {position_steps['z']} -> {len(sampler.z_range)} points")
    print(f"Orientation ranges:")
    print(f"  Roll:  {np.rad2deg(orientation_bounds['roll'])} step {np.rad2deg(orientation_steps['roll'])}° -> {len(sampler.roll_range)} points")
    print(f"  Pitch: {np.rad2deg(orientation_bounds['pitch'])} step {np.rad2deg(orientation_steps['pitch'])}° -> {len(sampler.pitch_range)} points")
    print(f"  Yaw:   {np.rad2deg(orientation_bounds['yaw'])} step {np.rad2deg(orientation_steps['yaw'])}° -> {len(sampler.yaw_range)} points")
    print(f"Reach filter: {ROBOT_MIN_REACH}m - {ROBOT_MAX_REACH}m")
    print(f"Poses filtered by reach: {sampler.filtered_samples}")
    print(f"Total poses to evaluate: {sampler.total_samples}")
    
    # === Process all poses ===
    reachable_poses = []  # (x, y, z, roll, pitch, yaw)
    reachable_joints = []  # Joint configurations
    unreachable_poses = []
    
    total_processed = 0
    start_time = time.time()
    
    print(f"\n--- Processing poses (batch size: {ik_batch_size}) ---")
    
    def esdf_checking():
        '''
        deprecated collision checking that may be helpful
        '''
        # For successful IK solutions, do additional collision check with ESDF
        # if ik_success.any():
        #     valid_idx = np.where(ik_success)[0]
        #     valid_joints = result.solution[valid_idx, 0, :]  # Take first solution
            
        #     # Additional collision check using ESDF
        #     # ESDF convention: positive = free space, negative = inside obstacle
        #     d_world, d_self = get_collision_signed_distance(curobo_fn, valid_joints, tensor_args)
        #     # print(d_world)
        #     # Use min to ensure ALL spheres are collision-free (positive distance)
        #     d_world_min = d_world.min(dim=-1)[0]
        #     # collision_free when: world dist > 0 (not in obstacle) AND self dist > 0 (no self-collision)
        #     collision_free = ((d_world_min > 0) & (d_self > 0)).cpu().numpy()
            
        #     # Debug output for first batch
        #     if total_processed == 0:
        #         print(f"\n--- DEBUG: First batch collision check ---")
        #         print(f"IK success: {ik_success.sum()}/{batch_size}")
        #         print(f"d_world shape: {d_world.shape}, d_self shape: {d_self.shape}")
        #         print(f"d_world_min range: [{d_world_min.min().item():.4f}, {d_world_min.max().item():.4f}]")
        #         print(f"d_self range: [{d_self.min().item():.4f}, {d_self.max().item():.4f}]")
        #         print(f"World collision-free (d_world_min > 0): {(d_world_min > 0).sum().item()}/{len(valid_idx)}")
        #         print(f"Self collision-free (d_self > 0): {(d_self > 0).sum().item()}/{len(valid_idx)}")
        #         print(f"Both collision-free: {collision_free.sum()}/{len(valid_idx)}")
        #         # Show a few sample poses and their distances
        #         for i in range(min(3, len(valid_idx))):
        #             idx = valid_idx[i]
        #             print(f"  Pose {i}: pos=({positions[idx][0]:.2f}, {positions[idx][1]:.2f}, {positions[idx][2]:.2f}), "
        #                   f"d_world_min={d_world_min[i].item():.4f}, d_self={d_self[i].item():.4f}, "
        #                   f"ok={collision_free[i]}")
        #         print("-------------------------------------------\n")
        return

    for positions, quaternions, euler_angles in sampler.generate_poses_batch(ik_batch_size):
        batch_size = len(positions)
        
        # Convert to torch tensors
        pos_tensor = torch.tensor(positions, device=tensor_args.device, dtype=tensor_args.dtype)
        quat_tensor = torch.tensor(quaternions, device=tensor_args.device, dtype=tensor_args.dtype)
        
        # Create goal pose for IK
        goal_pose = Pose(position=pos_tensor, quaternion=quat_tensor)
        # print(f"goal_pose: {goal_pose}")

        
        # Solve IK (includes collision checking)
        try:
            result = ik_solver.solve_batch(goal_pose)
        except Exception as e:
            print(f"Error solving IK: {e}")
            continue
        
        # Check which solutions are valid (IK success + collision-free)
        ik_success = result.success.cpu().numpy()
        print(f" IK success: {ik_success.sum()}/{batch_size}")
        
        # esdf checking would go here
            
            # Store results
        if ik_success.any():
            for i, idx in enumerate(np.where(ik_success)[0]):
                pose = np.concatenate([positions[idx], euler_angles[idx]])
                # if collision_free[i]:
                reachable_poses.append(pose)
                #     reachable_joints.append(valid_joints[i].cpu().numpy())
                # else:
                #     unreachable_poses.append(pose)
        
        # Add failed IK poses to unreachable
        failed_idx = np.where(~ik_success)[0]
        for idx in failed_idx:
            pose = np.concatenate([positions[idx], euler_angles[idx]])
            unreachable_poses.append(pose)
        
        total_processed += batch_size
        elapsed = time.time() - start_time
        rate = total_processed / elapsed
        remaining = (sampler.total_samples - total_processed) / rate if rate > 0 else 0
        
        print(f"\rProcessed: {total_processed}/{sampler.total_samples} "
              f"({100*total_processed/sampler.total_samples:.1f}%) "
              f"| Reachable: {len(reachable_poses)} "
              f"| Rate: {rate:.0f} poses/s "
              f"| ETA: {remaining/60:.1f} min", end="", flush=True)
    
    print()  # New line after progress
    
    # === Save Results ===
    elapsed_total = time.time() - start_time
    print(f"\n=== Results ===")
    print(f"Total time: {elapsed_total/60:.1f} minutes")
    print(f"Reachable poses: {len(reachable_poses)}/{sampler.total_samples} "
          f"({100*len(reachable_poses)/sampler.total_samples:.1f}%)")
    
    if reachable_poses:
        reachable_poses = np.array(reachable_poses)
        reachable_joints = np.array(reachable_joints)
        
        print(f"\nReachable workspace bounds:")
        print(f"  X: [{reachable_poses[:,0].min():.2f}, {reachable_poses[:,0].max():.2f}]")
        print(f"  Y: [{reachable_poses[:,1].min():.2f}, {reachable_poses[:,1].max():.2f}]")
        print(f"  Z: [{reachable_poses[:,2].min():.2f}, {reachable_poses[:,2].max():.2f}]")
        
        # Save files
        np.savetxt("reachable_poses.txt", reachable_poses, 
                   header="x y z roll pitch yaw")
        np.savetxt("reachable_joints.txt", reachable_joints,
                   header="joint_1_s joint_2_l joint_3_u joint_4_r joint_5_b joint_6_t")
        print(f"\nSaved: reachable_poses.txt, reachable_joints.txt")
    
    if unreachable_poses:
        unreachable_poses = np.array(unreachable_poses)
        np.savetxt("unreachable_poses.txt", unreachable_poses,
                   header="x y z roll pitch yaw")
        print(f"Saved: unreachable_poses.txt")
